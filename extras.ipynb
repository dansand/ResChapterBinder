{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A statistical test\n",
    "\n",
    "In this notebook we develop some more rigourous statistical tests around the efficient market hypothesis. \n",
    "\n",
    "Here we are attempting to falsify the null hypothsis, that that the daily market value changes are uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white noise as “uncorrelated”, which means that each value is independent of the others, and Brownian noise as “correlated”, because each value depends on the preceding value. \n",
    "\n",
    "In a Brownian noise signal, each value is the sum of the previous value and a random “step”, so we expect a strong serial correlation:\n",
    "\n",
    "A martingale is a sequence of random variables (i.e., a stochastic process) for which, at a particular time in the realized sequence, the expectation of the next value in the sequence is equal to the present observed value even given knowledge of all prior observed values.\n",
    "\n",
    "A necessary (but not sufficient) condition for the martingale hypothesis to hold is that the time series has no\n",
    "autocorrelation, also known as serial correlation, of any order. Note that autocorrelation is sensitive only to linear\n",
    "relationships\n",
    "\n",
    "First, consider the relevant literature on the dependence of stock market returns. Fama (1970) found that 22\n",
    "out of the 30 stocks of the DJIA exhibited positive daily serial correlation. \n",
    "\n",
    "Returns, rather than price are often used, are used as some of the statistical tests require a stationary variable. \n",
    "\n",
    "the runs test, a non-parametric statistical test that can be\n",
    "used to test for serial dependence, a lack of dependence being a necessary (but not sufficient) condition for the\n",
    "martingale hypothesis to hold. In contrast to autocorrelation, the runs test loses information because the magnitude\n",
    "of the returns is lost. However, whilst autocorrelation can detect only linear relationships, the runs test can detect\n",
    "both linear and non-linear relationships.\n",
    "\n",
    "If the number of runs is significantly higher or lower than expected, the hypothesis of statistical independence\n",
    "may be rejected. Consider the DJIA closing prices. There is no need to detrend the data. A run is a consecutive\n",
    "sequence of returns above (below) the mean return. The above runs test is performed on daily, weekly, monthly and\n",
    "annual returns, in chronological order.\n",
    "\n",
    " so-called runs-test also called Wald–Wolfowitz test [3,4]. This is a non-parametric test in which the null-hypothesis stating that the sequence gets produced in random fashion gets tested against the alternative hypothesis stating the opposite -- i.e., produced randomly. In detail, the null-hypothesis gets rejected in case of systematic or clustered arrangement of variables in a sequence. The test is called runs-test as it works with runs in a series -- e.g., the sequence \"ABBC\" has the three runs \"A\", \"BB\" and \"C\". Nonetheless, this test is only designed to work with dichotomous (binary) observations which is not the case in my sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serial_corr(sig, lag=1):\n",
    "    n = len(sig)\n",
    "    y1 = sig[lag:]\n",
    "    y2 = sig[:n-lag]\n",
    "    corr = np.corrcoef(y1, y2, ddof=0)[0, 1]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serial_corr(follow,  lag=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9f474e5313a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#test on random data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mserial_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#test on random data\n",
    "test = np.random.randint(0,2,len(follow))\n",
    "serial_corr(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It detects where chunks begin, has some logic for the first and last chunk, \n",
    "#and simply computes differences between chunk starts and discards lengths corresponding to False chunks.\n",
    "\n",
    "runs = np.diff(np.where(np.concatenate(([follow[0]],\n",
    "                                     follow[:-1] != follow[1:],\n",
    "                                     [True])))[0])[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs = np.diff(np.where(follow[:-1] != follow[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "class Runs(object):\n",
    "    '''class for runs in a binary sequence\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like, 1d\n",
    "        data array,\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This was written as a more general class for runs. This has some redundant\n",
    "    calculations when only the runs_test is used.\n",
    "\n",
    "    TODO: make it lazy\n",
    "\n",
    "    The runs test could be generalized to more than 1d if there is a use case\n",
    "    for it.\n",
    "\n",
    "    This should be extended once I figure out what the distribution of runs\n",
    "    of any length k is.\n",
    "\n",
    "    The exact distribution for the runs test is also available but not yet\n",
    "    verified.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, x):\n",
    "        self.x = np.asarray(x)\n",
    "\n",
    "        self.runstart = runstart = np.nonzero(np.diff(np.r_[[-np.inf], x, [np.inf]]))[0]\n",
    "        self.runs = runs = np.diff(runstart)\n",
    "        self.runs_sign = runs_sign = x[runstart[:-1]]\n",
    "        self.runs_pos = runs[runs_sign==1]\n",
    "        self.runs_neg = runs[runs_sign==0]\n",
    "        self.runs_freqs = np.bincount(runs)\n",
    "        self.n_runs = len(self.runs)\n",
    "        self.n_pos = (x==1).sum()\n",
    "\n",
    "    def runs_test(self, correction=True):\n",
    "        '''basic version of runs test\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        correction: bool\n",
    "            Following the SAS manual, for samplesize below 50, the test\n",
    "            statistic is corrected by 0.5. This can be turned off with\n",
    "            correction=False, and was included to match R, tseries, which\n",
    "            does not use any correction.\n",
    "\n",
    "        pvalue based on normal distribution, with integer correction\n",
    "\n",
    "        '''\n",
    "        self.npo = npo = (self.runs_pos).sum()\n",
    "        self.nne = nne = (self.runs_neg).sum()\n",
    "\n",
    "        #n_r = self.n_runs\n",
    "        n = npo + nne\n",
    "        npn = npo * nne\n",
    "        rmean = 2. * npn / n + 1\n",
    "        rvar = 2. * npn * (2.*npn - n) / n**2. / (n-1.)\n",
    "        rstd = np.sqrt(rvar)\n",
    "        rdemean = self.n_runs - rmean\n",
    "        if n >= 50 or not correction:\n",
    "            z = rdemean\n",
    "        else:\n",
    "            if rdemean > 0.5:\n",
    "                z = rdemean - 0.5\n",
    "            elif rdemean < 0.5:\n",
    "                z = rdemean + 0.5\n",
    "            else:\n",
    "                z = 0.\n",
    "\n",
    "        z /= rstd\n",
    "        pval = 2 * stats.norm.sf(np.abs(z))\n",
    "        return z, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runguy = Runs(follow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runguy.runs_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(runguy.runs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(runguy.runs_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
